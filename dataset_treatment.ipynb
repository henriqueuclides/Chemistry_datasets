{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1185da3",
   "metadata": {},
   "source": [
    "## Data treatment\n",
    "### 12/09/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3ca65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load libs\n",
    "import os\n",
    "from ase.db import connect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from __future__ import annotations\n",
    "import os, json, sqlite3, re, math\n",
    "from functools import reduce\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from tqdm import tqdm \n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "# --- File Configuration ---\n",
    "C2DB_PATH = \"c2db.db\"\n",
    "MP2D_PATH = \"2dmatpedia_final.db\"\n",
    "OUTPUT_DB_PATH = \"combined_2d_database.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8f0c9",
   "metadata": {},
   "source": [
    "## Combine C2DB and 2DMatPedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d78e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old database file 'combined_2d_database.db' removed.\n",
      "Loaded 16504 unique prototypes from 'c2db.db'.\n",
      "Loaded 6159 unique prototypes from '2dmatpedia_final.db'.\n",
      "\n",
      "--- Prototype Summary ---\n",
      "C2DB exclusive: 15284\n",
      "2DMatPedia exclusive: 4939\n",
      "Common: 1220\n",
      "\n",
      "Creating new database at 'combined_2d_database.db'...\n",
      "\n",
      "--- Process Completed ---\n",
      "The new database 'combined_2d_database.db' was successfully created and contains 21443 entries.\n"
     ]
    }
   ],
   "source": [
    "# --- Helper Functions ---\n",
    "\n",
    "def get_prototypes_and_data(db_path: str):\n",
    "    \"\"\"\n",
    "    Reads an ASE database and returns two things:\n",
    "    1. A set with all unique prototypes (formula, sym_type, sym_val).\n",
    "    2. A dictionary mapping each prototype to the first corresponding 'row' found.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"WARNING: File not found: {db_path}\")\n",
    "        return set(), {}\n",
    "\n",
    "    prototypes = set()\n",
    "    proto_to_row_map = {}\n",
    "    db = connect(db_path)\n",
    "    \n",
    "    # Identify symmetry columns\n",
    "    try:\n",
    "        row_sample = next(db.select(limit=1))\n",
    "        keys = list(row_sample.key_value_pairs.keys()) + list(getattr(row_sample, 'data', {}).keys())\n",
    "    except StopIteration:\n",
    "        return set(), {}\n",
    "\n",
    "    num_col = next((c for c in [\"sg_number\", \"number\", \"lgnum\"] if c in keys), None)\n",
    "    sym_col = next((c for c in [\"international\", \"layergroup\"] if c in keys), None)\n",
    "\n",
    "    for row in db.select():\n",
    "        formula = row.get(\"formula_norm\", row.formula)\n",
    "        prototype = None\n",
    "        \n",
    "        if num_col and row.get(num_col) is not None:\n",
    "            try:\n",
    "                prototype = (formula, \"number\", str(int(row.get(num_col))))\n",
    "            except (ValueError, TypeError): pass\n",
    "        elif sym_col and row.get(sym_col) is not None:\n",
    "            try:\n",
    "                sym_symb = re.sub(r\"\\\\s+\", \"\", str(row.get(sym_col)).strip()).replace('\"', '').replace(\"'\", \"\")\n",
    "                if sym_symb:\n",
    "                    prototype = (formula, \"symbol\", sym_symb)\n",
    "            except (ValueError, TypeError): pass\n",
    "\n",
    "        if prototype:\n",
    "            prototypes.add(prototype)\n",
    "            if prototype not in proto_to_row_map:\n",
    "                proto_to_row_map[prototype] = row\n",
    "                \n",
    "    print(f\"Loaded {len(prototypes)} unique prototypes from '{db_path}'.\")\n",
    "    return prototypes, proto_to_row_map\n",
    "\n",
    "# --- Main Union Logic ---\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(OUTPUT_DB_PATH):\n",
    "        os.remove(OUTPUT_DB_PATH)\n",
    "        print(f\"Old database file '{OUTPUT_DB_PATH}' removed.\")\n",
    "\n",
    "    # 1. Load all data and prototypes from each DB\n",
    "    c2_prototypes, c2_map = get_prototypes_and_data(C2DB_PATH)\n",
    "    m2_prototypes, m2_map = get_prototypes_and_data(MP2D_PATH)\n",
    "\n",
    "    # 2. Identify prototype groups\n",
    "    common_prototypes = c2_prototypes.intersection(m2_prototypes)\n",
    "    c2_only_prototypes = c2_prototypes - m2_prototypes\n",
    "    m2_only_prototypes = m2_prototypes - c2_prototypes\n",
    "\n",
    "    print(\"\\n--- Prototype Summary ---\")\n",
    "    print(f\"C2DB exclusive: {len(c2_only_prototypes)}\")\n",
    "    print(f\"2DMatPedia exclusive: {len(m2_only_prototypes)}\")\n",
    "    print(f\"Common: {len(common_prototypes)}\")\n",
    "\n",
    "    # 3. Open the new database for writing\n",
    "    with connect(OUTPUT_DB_PATH) as new_db:\n",
    "        print(f\"\\nCreating new database at '{OUTPUT_DB_PATH}'...\")\n",
    "\n",
    "        # Process C2DB exclusive materials (copy as is)\n",
    "        for proto in c2_only_prototypes:\n",
    "            row = c2_map[proto]\n",
    "            new_db.write(row.toatoms(), key_value_pairs=row.key_value_pairs, data=row.get('data'))\n",
    "\n",
    "        # Process 2DMatPedia exclusive materials (with modifications)\n",
    "        for proto in m2_only_prototypes:\n",
    "            row = m2_map[proto]\n",
    "            atoms = row.toatoms()\n",
    "            kvp = dict(row.key_value_pairs) \n",
    "\n",
    "            # Rename 'bandgap' to 'gap'\n",
    "            if 'bandgap' in kvp:\n",
    "                kvp['gap'] = kvp.pop('bandgap')\n",
    "            \n",
    "            # Create 'is_magnetic' and then rename 'total_magnetization' to 'magmom'\n",
    "            if 'total_magnetization' in kvp:\n",
    "                mag = kvp['total_magnetization']\n",
    "                kvp['is_magnetic'] = bool(pd.notna(mag) and mag > 0.01)\n",
    "                # Now rename the original property\n",
    "                kvp['magmom_u'] = kvp.pop('total_magnetization')\n",
    "\n",
    "            # Rename 'decomposition_energy' to 'ehull'\n",
    "            if 'decomposition_energy' in kvp:\n",
    "                kvp['ehull'] = kvp.pop('decomposition_energy')\n",
    "            \n",
    "            new_db.write(atoms, key_value_pairs=kvp, data=row.get('data'))\n",
    "            \n",
    "        # Process common materials\n",
    "        for proto in common_prototypes:\n",
    "            c2_row = c2_map[proto]\n",
    "            m2_row = m2_map[proto]\n",
    "\n",
    "            atoms = c2_row.toatoms()\n",
    "            kvp = dict(c2_row.key_value_pairs)\n",
    "            \n",
    "            m2_kvp = m2_row.key_value_pairs\n",
    "            for key, value in m2_kvp.items():\n",
    "                if key != 'bandgap' and key not in kvp:\n",
    "                    kvp[f\"m2_{key}\"] = value \n",
    "\n",
    "            new_db.write(atoms, key_value_pairs=kvp, data=c2_row.get('data'))\n",
    "\n",
    "    print(\"\\n--- Process Completed ---\")\n",
    "    final_count = len(connect(OUTPUT_DB_PATH))\n",
    "    print(f\"The new database '{OUTPUT_DB_PATH}' was successfully created and contains {final_count} entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aef271",
   "metadata": {},
   "source": [
    "## Preprocessing, filtering and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1fcc9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old database file 'final_processed_database.db' removed.\n",
      "Starting processing of 'combined_2d_database.db'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21443 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21443/21443 [01:36<00:00, 222.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Complete ---\n",
      "Total structures read: 21443\n",
      "------------------------------\n",
      "Removed due to missing 'gap' or 'is_magnetic': 8090\n",
      "Removed due to instability (ehull > 0.1 eV/atom): 6043\n",
      "Removed due to invalid geometry (dist < 0.5 Å): 0\n",
      "Removed due to being duplicates (after standardization): 0\n",
      "------------------------------\n",
      "Total structures saved to 'final_processed_database.db': 7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "INPUT_DB = \"combined_2d_database.db\"\n",
    "OUTPUT_DB = \"final_processed_database.db\"\n",
    "\n",
    "# --- Filtering and Validation Criteria ---\n",
    "EHULL_THRESHOLD = 0.1  # eV/atom\n",
    "MIN_INTERATOMIC_DISTANCE = 0.5  # Angstroms (Å)\n",
    "\n",
    "def get_stability_value(row):\n",
    "    \"\"\"Extracts the stability value, looking for common keys.\"\"\"\n",
    "    kvp = row.key_value_pairs\n",
    "    # Prioritize 'ehull' from C2DB, then look for 2DMatPedia analogs\n",
    "    if 'ehull' in kvp and kvp['ehull'] is not None:\n",
    "        return kvp['ehull']\n",
    "    if 'm2_decomposition_energy' in kvp and kvp['m2_decomposition_energy'] is not None:\n",
    "        return kvp['m2_decomposition_energy']\n",
    "    return None # Returns None if no stability key is found\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(INPUT_DB):\n",
    "        print(f\"ERROR: Input database '{INPUT_DB}' not found.\")\n",
    "        exit()\n",
    "\n",
    "    if os.path.exists(OUTPUT_DB):\n",
    "        os.remove(OUTPUT_DB)\n",
    "        print(f\"Old database file '{OUTPUT_DB}' removed.\")\n",
    "\n",
    "    # Connect to databases\n",
    "    db_in = connect(INPUT_DB)\n",
    "    db_out = connect(OUTPUT_DB)\n",
    "\n",
    "    # Set to track already added structures and prevent duplicates\n",
    "    # We use a string representation of the standardized structure as a \"fingerprint\"\n",
    "    seen_structures_fingerprints = set()\n",
    "    \n",
    "    # Counters for the final report\n",
    "    total_read = 0\n",
    "    removed_missing_props = 0\n",
    "    removed_instability = 0\n",
    "    removed_invalid_geom = 0\n",
    "    removed_duplicates = 0\n",
    "    written_count = 0\n",
    "    \n",
    "    print(f\"Starting processing of '{INPUT_DB}'...\")\n",
    "    # The tqdm progress bar is useful for long processes\n",
    "    for row in tqdm(db_in.select(), total=len(db_in)):\n",
    "        total_read += 1\n",
    "        \n",
    "        # --- STEP 1: PROPERTY FILTERING ---\n",
    "        kvp = row.key_value_pairs\n",
    "        if kvp.get('gap') is None or kvp.get('is_magnetic') is None:\n",
    "            removed_missing_props += 1\n",
    "            continue\n",
    "            \n",
    "        stability_val = get_stability_value(row)\n",
    "        # Filter only if stability is known and above the threshold\n",
    "        if stability_val is not None and stability_val > EHULL_THRESHOLD:\n",
    "            removed_instability += 1\n",
    "            continue\n",
    "\n",
    "        # --- STEP 2: GEOMETRY STANDARDIZATION AND VALIDATION ---\n",
    "        try:\n",
    "            atoms = row.toatoms()\n",
    "            # Convert from ASE to Pymatgen to use its advanced tools\n",
    "            structure_pmg = AseAtomsAdaptor.get_structure(atoms)\n",
    "\n",
    "            # Standardize the cell to the conventional primitive (includes Niggli reduction)\n",
    "            sga = SpacegroupAnalyzer(structure_pmg, symprec=0.1)\n",
    "            standardized_structure = sga.get_primitive_standard_structure()\n",
    "            \n",
    "            # Validation: check minimum interatomic distance\n",
    "            # This check is only meaningful for structures with more than one atom.\n",
    "            if len(standardized_structure) > 1:\n",
    "                # Get all non-zero distances. Using the upper triangle (k=1) is efficient.\n",
    "                distances = standardized_structure.distance_matrix[np.triu_indices(len(standardized_structure), k=1)]\n",
    "                \n",
    "                # It's possible for the distances array to be empty if the structure is unusual,\n",
    "                # so we check before calling min().\n",
    "                if distances.size > 0:\n",
    "                    min_dist = np.min(distances)\n",
    "                    if min_dist < MIN_INTERATOMIC_DISTANCE:\n",
    "                        removed_invalid_geom += 1\n",
    "                        continue\n",
    "\n",
    "        except Exception as e:\n",
    "            # Skip structures that cause errors during conversion or analysis\n",
    "            # print(f\"Warning: Error processing structure ID {row.id} ({row.formula}): {e}\")\n",
    "            removed_invalid_geom += 1\n",
    "            continue\n",
    "\n",
    "        # --- STEP 3: DUPLICATE FILTERING ---\n",
    "        # Create a \"fingerprint\" of the standardized structure\n",
    "        # We use the formula and the string representation of the structure for greater robustness\n",
    "        fingerprint = (\n",
    "            standardized_structure.formula, \n",
    "            standardized_structure.to(fmt=\"cif\")\n",
    "        )\n",
    "\n",
    "        if fingerprint in seen_structures_fingerprints:\n",
    "            removed_duplicates += 1\n",
    "            continue\n",
    "        else:\n",
    "            seen_structures_fingerprints.add(fingerprint)\n",
    "\n",
    "        # --- STEP 4: SAVE TO NEW DATABASE ---\n",
    "        # Convert the standardized structure back to ASE format\n",
    "        final_atoms = AseAtomsAdaptor.get_atoms(standardized_structure)\n",
    "        \n",
    "        # Write the standardized structure with original properties\n",
    "        db_out.write(final_atoms, key_value_pairs=kvp, data=row.get('data'))\n",
    "        written_count += 1\n",
    "\n",
    "    # --- Final Report ---\n",
    "    print(\"\\n--- Processing Complete ---\")\n",
    "    print(f\"Total structures read: {total_read}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Removed due to missing 'gap' or 'is_magnetic': {removed_missing_props}\")\n",
    "    print(f\"Removed due to instability (ehull > {EHULL_THRESHOLD} eV/atom): {removed_instability}\")\n",
    "    print(f\"Removed due to invalid geometry (dist < {MIN_INTERATOMIC_DISTANCE} Å): {removed_invalid_geom}\")\n",
    "    print(f\"Removed due to being duplicates (after standardization): {removed_duplicates}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total structures saved to '{OUTPUT_DB}': {written_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
