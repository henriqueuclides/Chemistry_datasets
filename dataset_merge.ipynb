{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1185da3",
   "metadata": {},
   "source": [
    "## Dataset combination and filtering\n",
    "### 01/10/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3ca65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load libs\n",
    "import os\n",
    "from ase.db import connect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from __future__ import annotations\n",
    "import os, json, sqlite3, re, math\n",
    "from functools import reduce\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from tqdm import tqdm \n",
    "from scipy.stats import pearsonr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aef271",
   "metadata": {},
   "source": [
    "## Preprocessing, filtering, validation and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fcc9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing database: c2db.db ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering c2db.db: 100%|██████████| 16905/16905 [01:04<00:00, 261.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Report for c2db.db ---\n",
      "Total structures read: 16905\n",
      "Removed due to instability ('ehull' > 0.1 eV/atom): 11217\n",
      "Removed due to invalid geometry (dist < 0.5 Å): 0\n",
      "Removed due to being duplicates: 0\n",
      "------------------------------\n",
      "Total structures saved to 'c2db_filtered.db': 5688\n",
      "\n",
      "--- Processing database: 2dmatpedia_final.db ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering 2dmatpedia_final.db: 100%|██████████| 6351/6351 [00:35<00:00, 177.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Report for 2dmatpedia_final.db ---\n",
      "Total structures read: 6351\n",
      "Removed due to instability ('ehull' > 0.1 eV/atom): 3631\n",
      "Removed due to invalid geometry (dist < 0.5 Å): 0\n",
      "Removed due to being duplicates: 0\n",
      "------------------------------\n",
      "Total structures saved to '2dmatpedia_filtered.db': 2720\n",
      "\n",
      "--- Combining filtered databases into final_combined_database.db ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining c2db_filtered.db: 5688it [00:06, 908.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5688 entries from 'c2db_filtered.db'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining 2dmatpedia_filtered.db: 2720it [00:02, 1089.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2720 entries from '2dmatpedia_filtered.db'.\n",
      "\n",
      "--- Workflow Complete ---\n",
      "The final combined database 'final_combined_database.db' was successfully created.\n",
      "It contains a total of 8408 high-quality, unique structures with harmonized properties.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Main Configuration ---\n",
    "\n",
    "# --- INPUT FILES ---\n",
    "# Original, unprocessed databases\n",
    "C2DB_PATH = \"c2db.db\"\n",
    "MP2D_PATH = \"2dmatpedia_final.db\" # Using the name from your provided code\n",
    "\n",
    "# --- INTERMEDIATE FILES ---\n",
    "# Databases after filtering and processing\n",
    "FILTERED_C2DB_PATH = \"c2db_filtered.db\"\n",
    "FILTERED_MP2D_PATH = \"2dmatpedia_filtered.db\"\n",
    "\n",
    "# --- FINAL OUTPUT FILE ---\n",
    "FINAL_COMBINED_DB_PATH = \"final_combined_database.db\"\n",
    "\n",
    "# --- Filtering and Validation Criteria ---\n",
    "EHULL_THRESHOLD = 0.1  # eV/atom\n",
    "MIN_INTERATOMIC_DISTANCE = 0.5  # Angstroms (Å)\n",
    "\n",
    "\n",
    "def process_and_filter_database(input_db_path, output_db_path, stability_key, property_rename_map=None):\n",
    "    \"\"\"\n",
    "    Reads a database, renames properties, filters by stability and geometry,\n",
    "    standardizes structures, removes duplicates, and saves to a new database.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Processing database: {input_db_path} ---\")\n",
    "\n",
    "    if not os.path.exists(input_db_path):\n",
    "        print(f\"ERROR: Input database '{input_db_path}' not found. Skipping.\")\n",
    "        return\n",
    "\n",
    "    if os.path.exists(output_db_path):\n",
    "        os.remove(output_db_path)\n",
    "\n",
    "    db_in = connect(input_db_path)\n",
    "    db_out = connect(output_db_path)\n",
    "\n",
    "    seen_structures_fingerprints = set()\n",
    "    stats = {'read': 0, 'removed_instability': 0, 'removed_invalid_geom': 0, 'removed_duplicates': 0, 'written': 0}\n",
    "\n",
    "    for row in tqdm(db_in.select(), total=len(db_in), desc=f\"Filtering {os.path.basename(input_db_path)}\"):\n",
    "        stats['read'] += 1\n",
    "        kvp = dict(row.key_value_pairs)\n",
    "\n",
    "        # STEP 1: RENAME PROPERTIES\n",
    "        # If a rename map is provided, create a new dictionary with the updated keys.\n",
    "        if property_rename_map:\n",
    "            renamed_kvp = {}\n",
    "            for key, value in kvp.items():\n",
    "                new_key = property_rename_map.get(key, key) # Get new key or keep the old one\n",
    "                renamed_kvp[new_key] = value\n",
    "            kvp = renamed_kvp # Use the renamed dictionary for all subsequent steps\n",
    "\n",
    "        # STEP 2: STABILITY FILTERING\n",
    "        # This check now uses the potentially renamed stability key.\n",
    "        if stability_key in kvp and kvp[stability_key] is not None:\n",
    "            if kvp[stability_key] > EHULL_THRESHOLD:\n",
    "                stats['removed_instability'] += 1\n",
    "                continue\n",
    "        \n",
    "        # STEP 3: GEOMETRY STANDARDIZATION AND VALIDATION\n",
    "        try:\n",
    "            atoms = row.toatoms()\n",
    "            structure_pmg = AseAtomsAdaptor.get_structure(atoms)\n",
    "            sga = SpacegroupAnalyzer(structure_pmg, symprec=0.1)\n",
    "            standardized_structure = sga.get_primitive_standard_structure()\n",
    "            \n",
    "            if len(standardized_structure) > 1:\n",
    "                distances = standardized_structure.distance_matrix[np.triu_indices(len(standardized_structure), k=1)]\n",
    "                if distances.size > 0 and np.min(distances) < MIN_INTERATOMIC_DISTANCE:\n",
    "                    stats['removed_invalid_geom'] += 1\n",
    "                    continue\n",
    "        except Exception:\n",
    "            stats['removed_invalid_geom'] += 1\n",
    "            continue\n",
    "\n",
    "        # STEP 4: DUPLICATE FILTERING\n",
    "        fingerprint = (standardized_structure.formula, standardized_structure.to(fmt=\"cif\"))\n",
    "        if fingerprint in seen_structures_fingerprints:\n",
    "            stats['removed_duplicates'] += 1\n",
    "            continue\n",
    "        else:\n",
    "            seen_structures_fingerprints.add(fingerprint)\n",
    "\n",
    "        # STEP 5: SAVE TO NEW DATABASE\n",
    "        final_atoms = AseAtomsAdaptor.get_atoms(standardized_structure)\n",
    "        # The renamed kvp dictionary is saved here\n",
    "        db_out.write(final_atoms, key_value_pairs=kvp, data=row.get('data'))\n",
    "        stats['written'] += 1\n",
    "        \n",
    "    # --- Print Report for this database ---\n",
    "    print(f\"\\n--- Report for {input_db_path} ---\")\n",
    "    print(f\"Total structures read: {stats['read']}\")\n",
    "    print(f\"Removed due to instability ('{stability_key}' > {EHULL_THRESHOLD} eV/atom): {stats['removed_instability']}\")\n",
    "    print(f\"Removed due to invalid geometry (dist < {MIN_INTERATOMIC_DISTANCE} Å): {stats['removed_invalid_geom']}\")\n",
    "    print(f\"Removed due to being duplicates: {stats['removed_duplicates']}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total structures saved to '{output_db_path}': {stats['written']}\")\n",
    "\n",
    "\n",
    "def combine_databases(source_db_paths, final_db_path):\n",
    "    \"\"\"Combines multiple ASE databases into a single new database.\"\"\"\n",
    "    print(f\"\\n--- Combining filtered databases into {final_db_path} ---\")\n",
    "    if os.path.exists(final_db_path):\n",
    "        os.remove(final_db_path)\n",
    "\n",
    "    total_written = 0\n",
    "    with connect(final_db_path) as db_out:\n",
    "        for db_path in source_db_paths:\n",
    "            if not os.path.exists(db_path):\n",
    "                print(f\"WARNING: Filtered database '{db_path}' not found for combination. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            db_in = connect(db_path)\n",
    "            count = 0\n",
    "            for row in tqdm(db_in.select(), desc=f\"Combining {os.path.basename(db_path)}\"):\n",
    "                db_out.write(row.toatoms(), key_value_pairs=row.key_value_pairs, data=row.get('data'))\n",
    "                count += 1\n",
    "            print(f\"Added {count} entries from '{db_path}'.\")\n",
    "            total_written += count\n",
    "    \n",
    "    return total_written\n",
    "\n",
    "# --- Main Execution Workflow ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- STAGE 1: Process C2DB (no renaming needed) ---\n",
    "    process_and_filter_database(\n",
    "        input_db_path=C2DB_PATH,\n",
    "        output_db_path=FILTERED_C2DB_PATH,\n",
    "        stability_key='ehull',\n",
    "        property_rename_map=None # No changes here\n",
    "    )\n",
    "\n",
    "    # --- STAGE 2: Process 2DMatPedia (with property renaming) ---\n",
    "    mp2d_rename_map = {\n",
    "        'bandgap': 'gap',\n",
    "        'decomposition_energy': 'ehull',\n",
    "        'total_magnetization': 'magmom_u'\n",
    "    }\n",
    "    process_and_filter_database(\n",
    "        input_db_path=MP2D_PATH,\n",
    "        output_db_path=FILTERED_MP2D_PATH,\n",
    "        stability_key='ehull', # Use the NEW key name for the stability check\n",
    "        property_rename_map=mp2d_rename_map\n",
    "    )\n",
    "\n",
    "    # --- STAGE 3: Combine the filtered and harmonized databases ---\n",
    "    final_count = combine_databases(\n",
    "        source_db_paths=[FILTERED_C2DB_PATH, FILTERED_MP2D_PATH],\n",
    "        final_db_path=FINAL_COMBINED_DB_PATH\n",
    "    )\n",
    "\n",
    "    # --- Final Summary ---\n",
    "    print(\"\\n--- Workflow Complete ---\")\n",
    "    print(f\"The final combined database '{FINAL_COMBINED_DB_PATH}' was successfully created.\")\n",
    "    print(f\"It contains a total of {final_count} high-quality, unique structures with harmonized properties.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
